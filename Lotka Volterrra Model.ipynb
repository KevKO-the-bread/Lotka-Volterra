{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a758b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "VFGLVM: Multi-Frequency Comparison (Daily, Weekly, Monthly)\n",
    "===========================================================\n",
    "Gold ETF Market Cap vs Bitcoin Market Cap ONLY\n",
    "\n",
    "This script implements the Variable-Order Fractional Grey\n",
    "Lotka–Volterra Model (VFGLVM) in the style of Gatabazi et al. (2019),\n",
    "but adapted to gold-vs-bitcoin capital allocation instead of\n",
    "crypto transaction counts.\n",
    "\n",
    "High-level pipeline (ties directly to thesis Sections 3.2.*):\n",
    "\n",
    "Step 0. Data prep (OUR extension)\n",
    "    - Build Gold ETF AUM in USD and Bitcoin market cap in USD.\n",
    "    - Align to daily, optionally resample to weekly/monthly.\n",
    "    - Winsorize Bitcoin extremes, interpolate gold holdings.\n",
    "    - Median-scale each series so regression is numerically stable.\n",
    "      (Not in Gatabazi et al. 2019; needed here because the two assets live\n",
    "       on very different dollar scales.)\n",
    "\n",
    "Step 1. Discretize Lotka–Volterra\n",
    "    We use a one-step-ahead forecast form instead of continuous-time ODEs.\n",
    "    x_i(k+1) ~ f(Z_i(k), Z_j(k))\n",
    "    This matches the discrete VFGLVM forecasting equation.\n",
    "\n",
    "Step 2. Fractional accumulation (long memory)\n",
    "    We transform each raw series x_i into a memory-adjusted series\n",
    "    X_i^{[q(t)]}(k) using variable-order fractional accumulation with\n",
    "    Gamma-based weights.\n",
    "\n",
    "Step 3. Variable-order q(t) (adaptive memory)\n",
    "    We estimate q(t) from local slopes/volatility: fast, jumpy periods\n",
    "    => shorter memory; calm periods => longer memory. We then clip\n",
    "    q(t) into [0.3,0.7] and smooth it.\n",
    "    (We use a continuous q(t); Gatabazi et al. later summarize q(t)\n",
    "     piecewise by regime.)\n",
    "\n",
    "Step 4. Background value Z_i(k) (short-term stabilizer)\n",
    "    Z_i(k) = 0.5 * ( X_i^{[q(t)]}(k) + X_i^{[q(t)]}(k-1) )\n",
    "    This filters out one-step jitters and gives the \"effective state\"\n",
    "    of each asset at time k.\n",
    "\n",
    "Step 5. Fit VFGLVM parameters and forecast\n",
    "    For each asset i:\n",
    "       x_i(k+1) ≈ a_i Z_i(k)\n",
    "                  - b_i [Z_i(k)]^2\n",
    "                  - Σ_{j≠i} C_ij Z_i(k) Z_j(k)\n",
    "    We estimate (a_i, b_i, C_ij) via (ridge-stabilized) least squares.\n",
    "    Gatabazi et al. (2019) use plain least squares; we add a tiny ridge\n",
    "    alpha=1e-5 just to avoid numerical blow-ups.\n",
    "\n",
    "After fitting we:\n",
    "    - Re-scale fitted values back to USD.\n",
    "    - Compute MAPE (as in Gatabazi et al. 2019), and also RMSE in $B.\n",
    "    - Plot Gold vs Bitcoin actual vs fitted at Daily / Weekly / Monthly.\n",
    "    - Dump summary tables.\n",
    "\n",
    "NOTE: We do not currently reproduce chaos diagnostics\n",
    "(Lyapunov exponents, phase portraits).\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import math, json\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from scipy.special import gammaln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e294653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIG / OUTPUT PATHS\n",
    "# ============================================================================\n",
    "\n",
    "START_DATE = \"2016-01-01\"\n",
    "END_DATE   = \"2025-09-30\"\n",
    "\n",
    "# Raw inputs:\n",
    "# - Gold ETF holdings in ounces (monthly or daily-ish file)\n",
    "# - LBMA gold price in USD/oz (daily JSON)\n",
    "# - Bitcoin market cap in USD (TSV with BTC / Market Cap (USD))\n",
    "PATH_GOLD_ETF   = r\"C:\\Users\\Kevin\\Downloads\\Thesis\\Data\\Gold Volume.xlsx\"\n",
    "PATH_LBMA_JSON  = r\"C:\\Users\\Kevin\\Downloads\\Thesis\\Data\\LBMA gold price 12.10.2025.json\"\n",
    "PATH_BTC_TSV    = r\"C:\\Users\\Kevin\\Downloads\\Thesis\\Data\\coin-metrics-new-chart.tsv.tsv\"\n",
    "\n",
    "# Winsorization on BTC cap to reduce flash-crash style outliers.\n",
    "WINSOR_PCT = 0.005\n",
    "\n",
    "OUTDIR = Path.cwd() / \"output\" / \"vfglvm_multi_frequency_btc_only\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Plot style\n",
    "mpl.rcParams.update({\n",
    "    \"figure.dpi\": 100,\n",
    "    \"axes.titlesize\": 11,\n",
    "    \"axes.labelsize\": 10,\n",
    "    \"xtick.labelsize\": 9,\n",
    "    \"ytick.labelsize\": 9,\n",
    "    \"grid.alpha\": 0.3,\n",
    "    \"grid.linestyle\": \":\",\n",
    "})\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3100ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: DISCRETE LOTKA–VOLTERRA SETUP\n",
    "# ----------------------------------------------------------------------------\n",
    "# THESIS REFERENCE: Section 3.2, Step 1\n",
    "# \n",
    "# Instead of continuous dX/dt = ..., we forecast one step ahead directly:\n",
    "#\n",
    "#   x_i(k+1) ≈ a_i Z_i(k) - b_i [Z_i(k)]^2 - Σ_{j≠i} C_ij Z_i(k) Z_j(k)\n",
    "#\n",
    "# where Z_i(k) is a smoothed/filtered state (Step 4), not the raw level.\n",
    "# \n",
    "# WHY THIS MATTERS:\n",
    "# Classic Lotka-Volterra uses continuous-time differential equations suitable\n",
    "# for stable biological populations. Financial markets have:\n",
    "#   - Discrete observations (daily, weekly, monthly)\n",
    "#   - Regime shifts and discontinuities\n",
    "#   - Noise that makes derivatives unstable\n",
    "# \n",
    "# The discrete forecasting form allows VFGLVM to:\n",
    "#   1. Work directly with observed time series (no derivative approximation)\n",
    "#   2. Make testable one-step-ahead predictions\n",
    "#   3. Incorporate memory-adjusted states Z_i(k) instead of raw prices\n",
    "#\n",
    "# This is how VFGLVM makes LV usable on noisy financial data.\n",
    "# Matches Gatabazi et al. (2019) Eq. (15).\n",
    "# ============================================================================\n",
    "\n",
    "def _as_array(x) -> np.ndarray:\n",
    "    return np.asarray(x, dtype=float)\n",
    "\n",
    "def _ridge(X: np.ndarray, y: np.ndarray, alpha: float = 1e-6) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Small ridge-regularized least squares.\n",
    "    \n",
    "    Gatabazi et al. (2019) solve with vanilla least squares: θ̂ = (B'B)^(-1)B'M\n",
    "    \n",
    "    We add alpha on the diagonal for numerical stability because Z_i, Z_i^2,\n",
    "    and Z_i*Z_j can be highly collinear in real market data.\n",
    "    \n",
    "    WHY RIDGE IS NEEDED (our extension):\n",
    "    1. COLLINEARITY: When gold and crypto trend together, Z_gold and Z_btc\n",
    "       become correlated, making (B'B) near-singular\n",
    "    2. SCALE DIFFERENCES: Even after median-scaling, variance properties differ\n",
    "    3. NUMERICAL SAFETY: α=1e-5 is negligible for parameter bias but prevents\n",
    "       matrix inversion failures\n",
    "    \n",
    "    This is a standard numerical practice when applying theoretical models\n",
    "    to real financial data.\n",
    "    \"\"\"\n",
    "    XtX = X.T @ X\n",
    "    XtX[np.diag_indices_from(XtX)] += alpha\n",
    "    Xty = X.T @ y\n",
    "    return np.linalg.solve(XtX, Xty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f64fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: VARIABLE-ORDER FRACTIONAL ACCUMULATION\n",
    "# ----------------------------------------------------------------------------\n",
    "# THESIS REFERENCE: Section 3.2, Step 2\n",
    "# \n",
    "# Given raw series x_i(k) we build\n",
    "#\n",
    "#   X_i^{[q(t)]}(k) = sum_{m=0..k} w_{k,m}( q(k) ) * x_i(m)\n",
    "#\n",
    "# where the weights w_{k,m} are Gamma-based. This is the discrete\n",
    "# variable-order fractional accumulation described in Gatabazi et al. (2019)\n",
    "# Eq. (10).\n",
    "# \n",
    "# INTUITION: This is a \"soft memory curve\"\n",
    "# - Recent points (m close to k) receive HIGH weight\n",
    "# - Older points (m far from k) receive LOWER weight (exponential fade)\n",
    "# - Nothing is thrown away completely (unlike moving averages)\n",
    "#\n",
    "# WHY THIS MATTERS FOR FINANCE:\n",
    "# Financial markets have LONG MEMORY:\n",
    "#   - Past bull markets influence current investor psychology\n",
    "#   - Historical volatility affects risk premia today\n",
    "#   - Previous regime characteristics carry forward\n",
    "#\n",
    "# Standard models (AR, MA) use FIXED exponential decay or truncation.\n",
    "# Fractional accumulation uses FLEXIBLE Gamma-weighted memory that:\n",
    "#   1. Adapts its decay rate via q(t)\n",
    "#   2. Never fully \"forgets\" the past (tail never hits zero)\n",
    "#   3. Produces smoother state variables for LV dynamics\n",
    "#\n",
    "# This implements grey system theory's core principle: extract stable\n",
    "# signals from noisy, limited data by controlled memory accumulation.\n",
    "# ============================================================================\n",
    "\n",
    "def fractional_accum_variable_order(x: np.ndarray,\n",
    "                                    q_t: np.ndarray,\n",
    "                                    max_lag: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build X_i^{[q(t)]}(k) using variable-order fractional accumulation.\n",
    "    We only sum back `max_lag` steps for efficiency/stability.\n",
    "\n",
    "    Gamma ratio:\n",
    "       coeff = Γ(q + dist) / [ Γ(q) Γ(dist+1) ]\n",
    "    matches fractional accumulation weights in Gatabazi et al. (2019) Eq. (9).\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - x: Raw time series (e.g., gold market cap in scaled units)\n",
    "    - q_t: Time-varying memory order (from Step 3)\n",
    "    - max_lag: How far back to accumulate (computational efficiency)\n",
    "    \n",
    "    RETURNS:\n",
    "    - X^{[q(t)]}: Memory-adjusted series incorporating weighted history\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    if len(q_t) != n:\n",
    "        raise ValueError(\"q_t must have same length as x\")\n",
    "\n",
    "    out = np.zeros(n, dtype=float)\n",
    "    for k in range(n):\n",
    "        # Local memory order at time k (varies over time)\n",
    "        qk = float(np.clip(q_t[k], 0.05, 0.95))\n",
    "\n",
    "        # Don't sum from 0..k if k is huge: cap by max_lag\n",
    "        i_start = max(0, k - max_lag + 1)\n",
    "        acc = 0.0\n",
    "        for i in range(i_start, k+1):\n",
    "            dist = k - i  # How far back in time\n",
    "            # Log Gamma ratio to avoid under/overflow\n",
    "            lg = gammaln(qk + dist) - gammaln(qk) - gammaln(dist + 1.0)\n",
    "            coeff = math.exp(lg)\n",
    "            acc += coeff * x[i]\n",
    "        out[k] = acc\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Helper for rolling slope (used in q(t) estimation, Step 3)\n",
    "# ============================================================================\n",
    "def _rolling_slope(y: np.ndarray, window: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Fit simple slopes over a rolling window.\n",
    "    \n",
    "    INTUITION:\n",
    "    - Big slope/vol spikes => the process is moving fast/jumpy \"right now\"\n",
    "    - We use that to shrink memory length q(t) in those regions\n",
    "    \n",
    "    This follows the idea in Gatabazi et al. (2019): q(t) reflects how fast\n",
    "    the underlying process is changing; faster change => different memory\n",
    "    regime.\n",
    "    \n",
    "    ECONOMIC INTERPRETATION:\n",
    "    - Steep slopes = rapid capital reallocation = shortened memory\n",
    "    - Flat slopes = stable regime = extended memory\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    out = np.full(n, np.nan)\n",
    "    t = np.arange(n, dtype=float)\n",
    "    for end in range(window - 1, n):\n",
    "        start = end - window + 1\n",
    "        yy = y[start:end+1]\n",
    "        tt = t[start:end+1]\n",
    "        mask = np.isfinite(yy)\n",
    "        if mask.sum() < max(2, window // 2):\n",
    "            continue\n",
    "        yyv = yy[mask]\n",
    "        ttv = tt[mask]\n",
    "        ym = np.mean(yyv)\n",
    "        tm = np.mean(ttv)\n",
    "        num = np.sum((ttv - tm) * (yyv - ym))\n",
    "        den = np.sum((ttv - tm)**2)\n",
    "        out[end] = np.nan if den == 0 else num / den\n",
    "    return out\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: ESTIMATE q(t) (ADAPTIVE MEMORY ORDER)\n",
    "# ----------------------------------------------------------------------------\n",
    "# THESIS REFERENCE: Section 3.2, Step 3\n",
    "#\n",
    "# q(t) controls how much past information we keep in Step 2.\n",
    "# \n",
    "# ECONOMIC INTUITION:\n",
    "# - When recent data are JUMPY/VOLATILE → SHORT memory (lower q)\n",
    "#   Example: 2020 COVID crash, 2021 crypto mania\n",
    "#   The system shouldn't trust old \"normal\" data in chaotic regimes\n",
    "#\n",
    "# - When recent data are CALM/TRENDING → LONG memory (higher q)\n",
    "#   Example: 2017-2019 stable gold range\n",
    "#   The system can safely incorporate historical context\n",
    "#\n",
    "# IMPLEMENTATION:\n",
    "# We:\n",
    "#   (a) Compute rolling slopes for each series (rate of change)\n",
    "#   (b) Take absolute values and average across assets → aggregate instability\n",
    "#   (c) INVERT the instability signal: high instability → low q\n",
    "#   (d) Clip to [0.3, 0.7] to prevent extreme memory behavior\n",
    "#   (e) Smooth q(t) across time to avoid discontinuous jumps\n",
    "#\n",
    "# DESIGN CHOICE: Continuous vs Piecewise q(t)\n",
    "# -------------------------------------------\n",
    "# Gatabazi et al. (2019) report PIECEWISE CONSTANT q(t) by regime:\n",
    "#   - Example from their Table: q=0.0196 for t≤1665, q=0.2717 for t>1665\n",
    "#   - This requires identifying regime break-points (structural break tests)\n",
    "#\n",
    "# We use CONTINUOUS q(t) instead, which:\n",
    "#   ✓ Adapts smoothly without arbitrary break-point selection\n",
    "#   ✓ Responds granularly to market phases\n",
    "#   ✓ Avoids overfitting to specific historical regimes\n",
    "#   ✗ May be less interpretable (no discrete \"regime labels\")\n",
    "#\n",
    "# Both approaches are valid. Continuous q(t) is more flexible for\n",
    "# out-of-sample forecasting where future regime breaks are unknown.\n",
    "#\n",
    "# This matches the spirit of Gatabazi et al. (2019) Section 2.1,\n",
    "# where they emphasize q(t) must vary with observed dynamics.\n",
    "# ============================================================================\n",
    "\n",
    "def estimate_q_t(series_matrix: np.ndarray,\n",
    "                 window: int,\n",
    "                 clip: Tuple[float,float]=(0.3,0.7),\n",
    "                 smooth_ma: int=4) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Estimate time-varying memory order q(t) from data dynamics.\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - series_matrix: (n_assets, n_periods) array of SCALED asset levels\n",
    "    - window: Rolling window for slope estimation (market dynamics detector)\n",
    "    - clip: (min_q, max_q) bounds for memory order\n",
    "    - smooth_ma: Smoothing window to prevent q(t) discontinuities\n",
    "    \n",
    "    RETURNS:\n",
    "    - q_t: (n_periods,) array of adaptive memory orders\n",
    "    \n",
    "    INTERPRETATION:\n",
    "    - q_t[k] ≈ 0.3 → Market is volatile, use SHORT memory\n",
    "    - q_t[k] ≈ 0.7 → Market is stable, use LONG memory\n",
    "    - q_t[k] in between → Transitional regime\n",
    "    \"\"\"\n",
    "    n, k = series_matrix.shape\n",
    "\n",
    "    # Safety tweak: avoid absurdly large windows\n",
    "    if window > k // 2:\n",
    "        window = max(4, k // 4)\n",
    "\n",
    "    # (a) Compute rolling slopes for each asset (rate of change measure)\n",
    "    slopes_abs = []\n",
    "    for i in range(n):\n",
    "        s = _rolling_slope(series_matrix[i], window)\n",
    "        slopes_abs.append(np.abs(s))\n",
    "\n",
    "    # (b) Aggregate instability across assets (market-wide volatility)\n",
    "    S = np.nanmean(np.vstack(slopes_abs), axis=0)\n",
    "\n",
    "    valid = S[np.isfinite(S)]\n",
    "    if len(valid) < 5:\n",
    "        # Fallback: constant mid-range memory if insufficient data\n",
    "        q = np.full(k, np.mean(clip))\n",
    "    else:\n",
    "        # (c) INVERT instability: high instability → low q\n",
    "        # Normalize instability to [0, 1] range\n",
    "        S_min = np.nanmin(valid)\n",
    "        S_max = np.nanmax(valid)\n",
    "        \n",
    "        if S_max > S_min:\n",
    "            # Normalized instability in [0, 1]\n",
    "            S_norm = (S - S_min) / (S_max - S_min)\n",
    "            S_norm = pd.Series(S_norm).ffill().bfill().values\n",
    "            \n",
    "            # INVERT: high instability (1) → low q (clip[0]=0.3)\n",
    "            #         low instability (0) → high q (clip[1]=0.7)\n",
    "            q = clip[1] - S_norm * (clip[1] - clip[0])\n",
    "        else:\n",
    "            # No variation in instability → constant memory\n",
    "            q = np.full(k, np.mean(clip))\n",
    "\n",
    "        # (d) Ensure bounds (already satisfied by construction, but enforce)\n",
    "        q = np.clip(q, clip[0], clip[1])\n",
    "\n",
    "    # (e) Smooth q(t) across time to prevent discontinuous jumps\n",
    "    # Financial insight: Memory characteristics shouldn't flip overnight\n",
    "    if smooth_ma and smooth_ma > 1:\n",
    "        q = pd.Series(q).rolling(smooth_ma, min_periods=1,\n",
    "                                 center=True).mean().values\n",
    "        q = np.clip(q, clip[0], clip[1])\n",
    "\n",
    "    return q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd35ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: BACKGROUND VALUE CONSTRUCTION\n",
    "# ----------------------------------------------------------------------------\n",
    "# THESIS REFERENCE: Section 3.2, Step 4\n",
    "#\n",
    "# After fractional accumulation we still smooth once more:\n",
    "#\n",
    "#   Z_i(k) = 0.5 * ( X_i^{[q(t)]}(k) + X_i^{[q(t)]}(k-1) )\n",
    "#\n",
    "# Gatabazi et al. call this the \"mean sequence\" or \"background value\".\n",
    "# \n",
    "# PURPOSE: Kill single-interval jumps while keeping medium-run structure\n",
    "#\n",
    "# WHY THIS IS NEEDED (Financial Market Reality):\n",
    "# ------------------------------------------------\n",
    "# Financial markets exhibit TWO TYPES of instability:\n",
    "#\n",
    "# 1. REGIME-LEVEL VOLATILITY (captured by q(t) in Step 3)\n",
    "#    Example: 2020 COVID crash changes market dynamics for months\n",
    "#    → q(t) drops system-wide, model uses shorter memory\n",
    "#\n",
    "# 2. TICK-LEVEL NOISE (filtered by Z_i(k) in Step 4)\n",
    "#    Example: Elon Musk tweets about Bitcoin at 3am\n",
    "#    → BTC jumps 8% in one hour, but doesn't reflect capital reallocation\n",
    "#\n",
    "# Even after fractional accumulation smooths long-term memory,\n",
    "# X_i^{[q(t)]}(k) can still contain short-term jitter from:\n",
    "#   - Flash crashes or single-tweet events in crypto\n",
    "#   - Gap openings between trading sessions in gold\n",
    "#   - High-frequency trading noise and algorithmic herding\n",
    "#   - Month-end rebalancing spikes\n",
    "#\n",
    "# The background value Z_i(k) acts as a SHORT-TERM stabilizer:\n",
    "#\n",
    "#   Z_i(k) = 0.5 * (X_i^{[q(t)]}(k) + X_i^{[q(t)]}(k-1))\n",
    "#\n",
    "# This averaging:\n",
    "#   ✓ Preserves medium-run trends (bull/bear markets)\n",
    "#   ✓ Preserves memory structure from Step 2\n",
    "#   ✓ Filters single-interval shocks (one-day events)\n",
    "#   ✓ Produces smoother \"effective state\" for LV dynamics\n",
    "#\n",
    "# RESULT: Z_i(k) represents \"where capital is actually positioned\"\n",
    "# after removing both long-term noise (via memory) and short-term\n",
    "# noise (via consecutive averaging).\n",
    "#\n",
    "# Gatabazi et al. (2019) Eq. (14) emphasizes this prevents one-step\n",
    "# jumps from distorting the LV interaction structure.\n",
    "# ============================================================================\n",
    "\n",
    "def build_Z_q(levels: List[np.ndarray],\n",
    "              q_t: np.ndarray,\n",
    "              max_lag: int) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Build background values Z_i(k) for each asset.\n",
    "    \n",
    "    PROCESS:\n",
    "    1. Apply fractional accumulation → X_i^{[q(t)]}(k) (long memory)\n",
    "    2. Average consecutive terms → Z_i(k) (short-term stabilization)\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - levels: list of raw scaled series [x_gold_scaled, x_btc_scaled]\n",
    "    - q_t: adaptive memory order over time (from Step 3)\n",
    "    - max_lag: memory horizon used in accumulation (computational bound)\n",
    "    \n",
    "    RETURNS:\n",
    "    - Xq: list of fractionally accumulated series\n",
    "    - Zq: list of background values (smoothed states for LV dynamics)\n",
    "    \"\"\"\n",
    "    # Step 2: Fractional accumulation for each asset i → X_i^{[q(t)]}(k)\n",
    "    Xq = [fractional_accum_variable_order(x, q_t, max_lag=max_lag)\n",
    "          for x in levels]\n",
    "\n",
    "    # Step 4: Background value Z_i(k) = average of consecutive accumulated terms\n",
    "    # This removes single-interval noise while preserving trends\n",
    "    Zq = []\n",
    "    for xq in Xq:\n",
    "        z = np.full_like(xq, np.nan)\n",
    "        z[1:] = 0.5 * (xq[1:] + xq[:-1])\n",
    "        Zq.append(z)\n",
    "\n",
    "    return Xq, Zq\n",
    "\n",
    "@dataclass\n",
    "class VFGLVMParams:\n",
    "    \"\"\"\n",
    "    Stores fitted parameters of the VFGLVM:\n",
    "    \n",
    "    a[i]:     Intrinsic growth rate of asset i\n",
    "              Economic interpretation: How strongly capital flows into asset i\n",
    "              when other assets are absent (standalone attractiveness)\n",
    "              \n",
    "    b[i]:     Self-saturation coefficient of asset i  \n",
    "              Economic interpretation: Diminishing returns as asset i grows\n",
    "              (crowding, liquidity constraints, profit-taking pressure)\n",
    "              \n",
    "    C[i,j]:   Cross-effect of asset j on asset i\n",
    "              Economic interpretation:\n",
    "              - C[i,j] > 0: Asset j crowds out asset i (competition)\n",
    "              - C[i,j] < 0: Asset j helps asset i (co-movement, complementarity)\n",
    "              - C[i,j] ≈ 0: Assets are independent\n",
    "    \n",
    "    These match the LV framework: growth, self-limitation, interaction.\n",
    "    See Gatabazi et al. (2019) Section 2.2 for formal definitions.\n",
    "    \"\"\"\n",
    "    a: np.ndarray\n",
    "    b: np.ndarray\n",
    "    C: np.ndarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e4271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 0: DATA PREP / PANEL CONSTRUCTION (OUR EXTENSION)\n",
    "# ----------------------------------------------------------------------------\n",
    "# We are not modeling transaction counts. We are modeling *capital allocation*:\n",
    "#   - Gold series: Gold ETF AUM in USD\n",
    "#   - Bitcoin series: BTC market cap in USD\n",
    "#\n",
    "# We:\n",
    "#   - interpolate gold ETF ounces daily between reported month-ends\n",
    "#   - multiply by daily LBMA gold price to get gold AUM in USD\n",
    "#   - take BTC market cap\n",
    "#   - align them on the same calendar\n",
    "#   - optionally resample to weekly/monthly\n",
    "#   - winsorize BTC tail moves\n",
    "#   - median-scale before fitting (so magnitudes are ~O(1))\n",
    "# ============================================================================\n",
    "\n",
    "def month_end_index(start_date: str, end_date: str) -> pd.DatetimeIndex:\n",
    "    return pd.date_range(pd.to_datetime(start_date),\n",
    "                         pd.to_datetime(end_date),\n",
    "                         freq=\"ME\")\n",
    "\n",
    "def daily_index(start_date: str, end_date: str) -> pd.DatetimeIndex:\n",
    "    return pd.date_range(pd.to_datetime(start_date),\n",
    "                         pd.to_datetime(end_date),\n",
    "                         freq=\"D\")\n",
    "\n",
    "def align_level_to_eom(series: pd.Series,\n",
    "                       eom_idx: pd.DatetimeIndex) -> pd.Series:\n",
    "    \"\"\"\n",
    "    For each month-end timestamp in eom_idx, grab the last known\n",
    "    value in 'series' up to that date.\n",
    "    \"\"\"\n",
    "    series = series.sort_index()\n",
    "    out = []\n",
    "    for ts in eom_idx:\n",
    "        hist = series.loc[series.index <= ts]\n",
    "        out.append(hist.iloc[-1] if len(hist) else np.nan)\n",
    "    return pd.Series(out, index=eom_idx)\n",
    "\n",
    "def _winsorize(s: pd.Series, p: float | None) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Clip extreme tails. Helps keep 'flash crash' type events\n",
    "    from wrecking q(t) and regression stability.\n",
    "    \"\"\"\n",
    "    if p is None or p <= 0:\n",
    "        return s\n",
    "    lo = s.quantile(p)\n",
    "    hi = s.quantile(1 - p)\n",
    "    return s.clip(lower=lo, upper=hi)\n",
    "\n",
    "def load_gold_etf_holdings_monthly(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load gold ETF holdings in OUNCES and keep month-end levels.\n",
    "    Result: DataFrame[gold_etf_ounces] indexed by month-end.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(path)\n",
    "    df = df[[\"Date\", \"Ounces\"]].copy()\n",
    "\n",
    "    df[\"Date\"]   = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "    df[\"Ounces\"] = pd.to_numeric(df[\"Ounces\"], errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna().sort_values(\"Date\")\n",
    "    df = df[(df[\"Date\"] >= pd.to_datetime(START_DATE)) &\n",
    "            (df[\"Date\"] <= pd.to_datetime(END_DATE))]\n",
    "\n",
    "    eom_idx = month_end_index(START_DATE, END_DATE)\n",
    "    s_oz = pd.Series(df[\"Ounces\"].values, index=df[\"Date\"].values)\n",
    "    s_eom_oz = align_level_to_eom(s_oz, eom_idx)\n",
    "\n",
    "    return pd.DataFrame({\"gold_etf_ounces\": s_eom_oz}, index=eom_idx)\n",
    "\n",
    "def load_lbma_gold_price_daily(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    LBMA gold price per ounce in USD, daily.\n",
    "    We forward-fill to get a full daily series.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    rows = []\n",
    "    for rec in data:\n",
    "        d = rec.get(\"d\")\n",
    "        vals = rec.get(\"v\", [])\n",
    "        usd = vals[0] if isinstance(vals, list) and len(vals) > 0 else None\n",
    "        rows.append((d, usd))\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"date\", \"usd_per_oz\"])\n",
    "    df[\"date\"]        = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    df[\"usd_per_oz\"]  = pd.to_numeric(df[\"usd_per_oz\"], errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna().sort_values(\"date\")\n",
    "    df = df[(df[\"date\"] >= pd.to_datetime(START_DATE)) &\n",
    "            (df[\"date\"] <= pd.to_datetime(END_DATE))]\n",
    "    df = df.set_index(\"date\")\n",
    "\n",
    "    full_idx  = daily_index(START_DATE, END_DATE)\n",
    "    df_daily  = df.reindex(full_idx).ffill()\n",
    "    df_daily.columns = [\"gold_usd_per_oz\"]\n",
    "    return df_daily\n",
    "\n",
    "def load_bitcoin_daily(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    DAILY Bitcoin market cap (USD). We drop ETH completely.\n",
    "    Column of interest: 'BTC / Market Cap (USD)' -> btc_mcap_usd.\n",
    "    \"\"\"\n",
    "    encodings = ['utf-16','utf-16-le','utf-16-be','utf-8-sig','latin-1']\n",
    "    df = None\n",
    "    for enc in encodings:\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep=\"\\t\", encoding=enc)\n",
    "            break\n",
    "        except (UnicodeDecodeError, UnicodeError):\n",
    "            continue\n",
    "    if df is None:\n",
    "        raise ValueError(\"Could not read BTC TSV.\")\n",
    "\n",
    "    need = [\"Time\", \"BTC / Market Cap (USD)\"]\n",
    "    for c in need:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"Missing '{c}' in BTC TSV. Found {list(df.columns)}\")\n",
    "\n",
    "    df = df[need].copy()\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], errors=\"coerce\")\n",
    "    df[\"BTC / Market Cap (USD)\"] = pd.to_numeric(\n",
    "        df[\"BTC / Market Cap (USD)\"], errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    df = df.dropna(subset=[\"Time\"]).sort_values(\"Time\")\n",
    "    df = df[(df[\"Time\"] >= pd.to_datetime(START_DATE)) &\n",
    "            (df[\"Time\"] <= pd.to_datetime(END_DATE))]\n",
    "    df = df.set_index(\"Time\")\n",
    "\n",
    "    # Resample to a regular daily calendar (last obs per day)\n",
    "    daily = df.resample(\"D\").last()\n",
    "\n",
    "    # Winsorize BTC extremes to limit insane single-tick jumps\n",
    "    if WINSOR_PCT and WINSOR_PCT > 0:\n",
    "        daily[\"BTC / Market Cap (USD)\"] = _winsorize(\n",
    "            daily[\"BTC / Market Cap (USD)\"], WINSOR_PCT\n",
    "        )\n",
    "\n",
    "    daily = daily.rename(columns={\n",
    "        \"BTC / Market Cap (USD)\": \"btc_mcap_usd\"\n",
    "    })\n",
    "\n",
    "    return daily[[\"btc_mcap_usd\"]]\n",
    "\n",
    "def interpolate_ounces_daily(gold_ounces_monthly: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Gold ETF ounces are typically monthly (end-of-month).\n",
    "    We linearly interpolate to daily to match Bitcoin frequency.\n",
    "    \"\"\"\n",
    "    s_monthly = gold_ounces_monthly[\"gold_etf_ounces\"].dropna()\n",
    "    full_idx  = daily_index(START_DATE, END_DATE)\n",
    "    s_daily   = s_monthly.reindex(full_idx)\n",
    "    s_daily   = s_daily.interpolate(method=\"time\")\n",
    "    return pd.DataFrame({\"gold_etf_ounces_daily\": s_daily}, index=full_idx)\n",
    "\n",
    "def build_gold_aum_daily(ounces_daily: pd.DataFrame,\n",
    "                         gold_price_daily: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Gold AUM in USD = (ETF ounces) * (USD per ounce).\n",
    "    That's our \"capital stored in gold\" series.\n",
    "    \"\"\"\n",
    "    df = ounces_daily.join(gold_price_daily, how=\"inner\")\n",
    "    df[\"gold_etf_mcap_usd\"] = (\n",
    "        df[\"gold_etf_ounces_daily\"] * df[\"gold_usd_per_oz\"]\n",
    "    )\n",
    "    return df[[\"gold_etf_mcap_usd\"]]\n",
    "\n",
    "def build_panel_and_scale(gold_aum: pd.DataFrame,\n",
    "                          btc: pd.DataFrame,\n",
    "                          freq_name: str) -> Tuple[pd.DataFrame,\n",
    "                                                   pd.DataFrame,\n",
    "                                                   Dict]:\n",
    "    \"\"\"\n",
    "    Create aligned panel for a given frequency (daily/weekly/monthly):\n",
    "      - Join gold AUM and BTC mcap\n",
    "      - Drop NaNs\n",
    "      - MEDIAN-SCALE each series so typical value is ~1.0\n",
    "\n",
    "    Scaling detail (our extension):\n",
    "    We divide each asset by its own median market cap in that frequency\n",
    "    window. This puts both assets on comparable O(1) scale so that\n",
    "    parameter estimates (a,b,C) aren't dominated by the bigger series.\n",
    "    We'll multiply back later to get USD predictions.\n",
    "    \"\"\"\n",
    "    print(f\"\\n[{freq_name}] Building scaled panel...\")\n",
    "\n",
    "    df = gold_aum.join(btc[[\"btc_mcap_usd\"]], how=\"inner\").sort_index()\n",
    "\n",
    "    panel_raw = df[[\"gold_etf_mcap_usd\", \"btc_mcap_usd\"]].dropna(how=\"any\").copy()\n",
    "\n",
    "    eps = 1e-12\n",
    "    med_gold = np.nanmedian(panel_raw[\"gold_etf_mcap_usd\"])\n",
    "    med_btc  = np.nanmedian(panel_raw[\"btc_mcap_usd\"])\n",
    "\n",
    "    # fallback in degenerate cases\n",
    "    if not (np.isfinite(med_gold) and med_gold > 0): med_gold = 1.0\n",
    "    if not (np.isfinite(med_btc)  and med_btc  > 0): med_btc  = 1.0\n",
    "\n",
    "    panel_scaled = pd.DataFrame({\n",
    "        \"x\": panel_raw[\"gold_etf_mcap_usd\"] / (med_gold + eps),\n",
    "        \"y\": panel_raw[\"btc_mcap_usd\"]      / (med_btc  + eps),\n",
    "    }, index=panel_raw.index)\n",
    "\n",
    "    scale_info = {\n",
    "        \"gold_median_usd\": med_gold,\n",
    "        \"btc_median_usd\":  med_btc,\n",
    "    }\n",
    "\n",
    "    print(f\"   {freq_name}: {len(panel_scaled)} observations\")\n",
    "    print(f\"   Gold median:    {med_gold:.3g} USD\")\n",
    "    print(f\"   Bitcoin median: {med_btc:.3g} USD\")\n",
    "\n",
    "    return panel_raw, panel_scaled, scale_info\n",
    "\n",
    "def build_monthly():\n",
    "    \"\"\"\n",
    "    Monthly panel:\n",
    "    - Gold ETF AUM at month-end.\n",
    "    - BTC market cap at month-end.\n",
    "    - Build scaled panel.\n",
    "    \"\"\"\n",
    "    gold_ounces_m = load_gold_etf_holdings_monthly(PATH_GOLD_ETF)\n",
    "    lbma_price_d  = load_lbma_gold_price_daily(PATH_LBMA_JSON)\n",
    "    lbma_monthly  = lbma_price_d.resample(\"ME\").last()\n",
    "\n",
    "    gold_aum = gold_ounces_m.join(lbma_monthly, how=\"inner\")\n",
    "    gold_aum[\"gold_etf_mcap_usd\"] = (\n",
    "        gold_aum[\"gold_etf_ounces\"] * gold_aum[\"gold_usd_per_oz\"]\n",
    "    )\n",
    "    gold_aum = gold_aum[[\"gold_etf_mcap_usd\"]]\n",
    "\n",
    "    btc_d       = load_bitcoin_daily(PATH_BTC_TSV)\n",
    "    btc_monthly = btc_d.resample(\"ME\").last()\n",
    "\n",
    "    return build_panel_and_scale(gold_aum, btc_monthly, \"MONTHLY\")\n",
    "\n",
    "def build_weekly():\n",
    "    \"\"\"\n",
    "    Weekly panel:\n",
    "    - First build daily gold AUM (interpolated ounces * daily price).\n",
    "    - Then downsample both gold and BTC to W-FRI (Friday close).\n",
    "    \"\"\"\n",
    "    gold_ounces_m = load_gold_etf_holdings_monthly(PATH_GOLD_ETF)\n",
    "    gold_ounces_d = interpolate_ounces_daily(gold_ounces_m)\n",
    "    lbma_price_d  = load_lbma_gold_price_daily(PATH_LBMA_JSON)\n",
    "    gold_aum_d    = build_gold_aum_daily(gold_ounces_d, lbma_price_d)\n",
    "\n",
    "    btc_d = load_bitcoin_daily(PATH_BTC_TSV)\n",
    "\n",
    "    gold_aum_w = gold_aum_d.resample(\"W-FRI\").last()\n",
    "    btc_w      = btc_d.resample(\"W-FRI\").last()\n",
    "\n",
    "    return build_panel_and_scale(gold_aum_w, btc_w, \"WEEKLY\")\n",
    "\n",
    "def build_daily():\n",
    "    \"\"\"\n",
    "    Daily panel:\n",
    "    - Daily gold AUM via interpolation+price.\n",
    "    - Daily BTC mcap.\n",
    "    \"\"\"\n",
    "    gold_ounces_m = load_gold_etf_holdings_monthly(PATH_GOLD_ETF)\n",
    "    gold_ounces_d = interpolate_ounces_daily(gold_ounces_m)\n",
    "    lbma_price_d  = load_lbma_gold_price_daily(PATH_LBMA_JSON)\n",
    "    gold_aum_d    = build_gold_aum_daily(gold_ounces_d, lbma_price_d)\n",
    "\n",
    "    btc_d = load_bitcoin_daily(PATH_BTC_TSV)\n",
    "\n",
    "    return build_panel_and_scale(gold_aum_d, btc_d, \"DAILY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: PARAMETER FITTING AND FORECAST\n",
    "# ----------------------------------------------------------------------------\n",
    "# THESIS REFERENCE: Section 3.2, Step 5\n",
    "#\n",
    "# We now estimate (a_i, b_i, C_ij) from the discrete VFGLVM equation:\n",
    "#\n",
    "#   x_i(k+1) ≈ a_i Z_i(k)\n",
    "#              - b_i [Z_i(k)]^2\n",
    "#              - Σ_{j≠i} C_ij Z_i(k) Z_j(k)\n",
    "#\n",
    "# For each asset i, we build a regression:\n",
    "#   target  = x_i(k+1)             [what we want to predict]\n",
    "#   columns = [ Z_i(k),            [linear growth term]\n",
    "#               -(Z_i(k))^2,       [self-saturation term]\n",
    "#               -(Z_i(k)*Z_j(k))   [cross-competition terms for j≠i]\n",
    "#             ]\n",
    "#\n",
    "# Then solve via least squares: θ̂ = (B'B)^(-1) B'M\n",
    "#\n",
    "# This mirrors Eq. (15) and Eq. (17) in Gatabazi et al. (2019).\n",
    "#\n",
    "# ADAPTATION: Ridge Regularization (Our Extension)\n",
    "# -------------------------------------------------\n",
    "# Gatabazi et al. use vanilla least squares in Eq. (17):\n",
    "#   θ̂ = (B'B)^(-1) B'M\n",
    "#\n",
    "# We add TINY ridge penalty (α=1e-5):\n",
    "#   θ̂ = (B'B + αI)^(-1) B'M\n",
    "#\n",
    "# WHY RIDGE IS NEEDED:\n",
    "# 1. COLLINEARITY IN FINANCIAL DATA:\n",
    "#    - Z_gold and Z_btc can trend together (risk-on/risk-off regimes)\n",
    "#    - Z_i and Z_i^2 are mechanically correlated\n",
    "#    - Z_i*Z_j interaction terms compound correlations\n",
    "#    → (B'B) can become near-singular, causing numerical instability\n",
    "#\n",
    "# 2. SCALE DIFFERENCES:\n",
    "#    Even after median-scaling, gold (stable) and crypto (volatile)\n",
    "#    have different variance properties that stress matrix inversion\n",
    "#\n",
    "# 3. NUMERICAL SAFETY:\n",
    "#    α=1e-5 is chosen to be NEGLIGIBLE for parameter bias\n",
    "#    (shrinks estimates by <0.001%) but prevents:\n",
    "#    - Matrix inversion failures\n",
    "#    - Extreme parameter values from near-collinearity\n",
    "#    - Numerical overflow in forecasts\n",
    "#\n",
    "# This is standard practice when applying theoretical models to real data.\n",
    "# The economic interpretation of parameters remains unchanged.\n",
    "#\n",
    "# ECONOMIC INTERPRETATION OF FITTED PARAMETERS:\n",
    "# ----------------------------------------------\n",
    "# After solving, we obtain for each asset i:\n",
    "#\n",
    "# a_i > 0:   Intrinsic growth (capital attraction when standalone)\n",
    "#            Large a_i → Strong investor demand for asset i\n",
    "#\n",
    "# b_i > 0:   Self-saturation (crowding diminishes returns)\n",
    "#            Large b_i → Asset quickly hits diminishing returns\n",
    "#\n",
    "# C_ij > 0:  Asset j crowds out asset i (substitution/competition)\n",
    "#            Example: C_gold,btc > 0 means Bitcoin steals gold flows\n",
    "#\n",
    "# C_ij < 0:  Asset j helps asset i (complementarity/co-movement)\n",
    "#            Example: C_gold,btc < 0 means Bitcoin and gold rise together\n",
    "#\n",
    "# C_ij ≈ 0:  Assets are independent (no capital reallocation between them)\n",
    "#\n",
    "# These parameters quantify the competitive dynamics between gold and crypto.\n",
    "# ============================================================================\n",
    "\n",
    "def fit_vfglvm_params(levels: List[np.ndarray],\n",
    "                      Zq: List[np.ndarray],\n",
    "                      ridge_alpha: float = 1e-5) -> VFGLVMParams:\n",
    "    \"\"\"\n",
    "    Estimate VFGLVM parameters via ridge-regularized least squares.\n",
    "    \n",
    "    PROCESS:\n",
    "    For each asset i:\n",
    "      1. Build design matrix B with [Z_i, -Z_i^2, -Z_i*Z_j for j≠i]\n",
    "      2. Set target vector M = x_i(k+1)\n",
    "      3. Solve: θ̂ = (B'B + αI)^(-1) B'M\n",
    "      4. Extract a_i, b_i, C_ij from θ̂\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - levels: List of raw scaled series [x_gold, x_btc]\n",
    "    - Zq: List of background values from Step 4\n",
    "    - ridge_alpha: Regularization strength (default 1e-5 for numerical stability)\n",
    "    \n",
    "    RETURNS:\n",
    "    - VFGLVMParams object with fitted a, b, C arrays\n",
    "    \"\"\"\n",
    "    n = len(levels)\n",
    "    T = min(len(x) for x in levels)\n",
    "\n",
    "    X0 = np.vstack([_as_array(x) for x in levels])[:, :T]  # raw scaled x_i(k)\n",
    "    Z  = np.vstack([_as_array(z) for z in Zq])[:, :T]      # background Z_i(k)\n",
    "\n",
    "    # Use indices k where we have both Z_i(k) and x_i(k+1)\n",
    "    idx_all = np.arange(1, T-1)\n",
    "    mask = np.ones(len(idx_all), dtype=bool)\n",
    "    for i in range(n):\n",
    "        mask &= np.isfinite(Z[i, idx_all]) & np.isfinite(X0[i, idx_all+1])\n",
    "    idx = idx_all[mask]\n",
    "    \n",
    "    if len(idx) < 5:\n",
    "        raise RuntimeError(f\"Not enough usable points to fit VFGLVM ({len(idx)})\")\n",
    "\n",
    "    a_hat = np.zeros(n)\n",
    "    b_hat = np.zeros(n)\n",
    "    C_hat = np.zeros((n, n))\n",
    "\n",
    "    # Fit each asset's equation separately\n",
    "    for i in range(n):\n",
    "        zi = Z[i, idx]\n",
    "\n",
    "        # Build design matrix B:\n",
    "        # Column 1: Z_i(k)           → coefficient a_i\n",
    "        # Column 2: -Z_i(k)^2        → coefficient b_i  \n",
    "        # Column 3+: -Z_i(k)*Z_j(k)  → coefficients C_ij for j≠i\n",
    "        cols = [zi, -(zi**2)]\n",
    "\n",
    "        # Add cross terms with all other assets\n",
    "        for j in range(n):\n",
    "            if j == i:\n",
    "                continue\n",
    "            zj = Z[j, idx]\n",
    "            cols.append(-(zi * zj))\n",
    "\n",
    "        Bi = np.column_stack(cols)\n",
    "        Mi = X0[i, idx+1]  # x_i(k+1) is the target\n",
    "\n",
    "        # Ridge-regularized least squares\n",
    "        theta = _ridge(Bi, Mi, alpha=ridge_alpha)\n",
    "\n",
    "        # Extract parameters\n",
    "        a_hat[i] = theta[0]\n",
    "        b_hat[i] = theta[1]\n",
    "\n",
    "        c_idx = 2\n",
    "        for j in range(n):\n",
    "            if j == i:\n",
    "                continue\n",
    "            C_hat[i, j] = theta[c_idx]\n",
    "            c_idx += 1\n",
    "\n",
    "    return VFGLVMParams(a=a_hat, b=b_hat, C=C_hat)\n",
    "\n",
    "def vfglvm_fitted_values(params: VFGLVMParams,\n",
    "                         levels: List[np.ndarray],\n",
    "                         Zq: List[np.ndarray]) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Produce in-sample 1-step-ahead fitted values:\n",
    "    ̂x_i(k+1) = a_i Z_i(k) - b_i [Z_i(k)]^2 - Σ_j C_ij Z_i(k)Z_j(k)\n",
    "    \n",
    "    This generates the model's predictions that we compare to actual values\n",
    "    for computing MAPE, RMSE, etc.\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - params: Fitted VFGLVMParams from fit_vfglvm_params\n",
    "    - levels: List of raw scaled series (for dimensionality)\n",
    "    - Zq: List of background values (the state variables)\n",
    "    \n",
    "    RETURNS:\n",
    "    - List of fitted series in scaled units (will be rescaled to USD later)\n",
    "    \"\"\"\n",
    "    n = len(levels)\n",
    "    T = len(levels[0])\n",
    "    fitted = [np.full(T, np.nan) for _ in range(n)]\n",
    "\n",
    "    for k in range(1, T):\n",
    "        z_k = np.array([Zq[i][k] for i in range(n)])\n",
    "        if not np.all(np.isfinite(z_k)):\n",
    "            continue\n",
    "        for i in range(n):\n",
    "            # Apply VFGLVM equation with fitted parameters\n",
    "            pred = params.a[i] * z_k[i] - params.b[i] * (z_k[i]**2)\n",
    "            for j in range(n):\n",
    "                if j != i:\n",
    "                    pred -= params.C[i, j] * z_k[i] * z_k[j]\n",
    "            if k+1 < T:\n",
    "                fitted[i][k+1] = pred\n",
    "    return fitted\n",
    "\n",
    "def _default_max_lag(n_obs: int) -> int:\n",
    "    \"\"\"\n",
    "    Cap how far back we look in the fractional accumulation.\n",
    "    \n",
    "    RATIONALE:\n",
    "    - Memory is long but not infinite\n",
    "    - Computational efficiency (O(n²) otherwise)\n",
    "    - Numerical stability (Gamma weights decay to zero anyway)\n",
    "    \n",
    "    HEURISTIC:\n",
    "    - Short series (≤200 obs): 36-step memory (~1 month daily data)\n",
    "    - Long series (>200 obs): 156-step memory (~6 months daily data)\n",
    "    \"\"\"\n",
    "    return 36 if n_obs <= 200 else 156\n",
    "\n",
    "def metrics_levels(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute error metrics for model evaluation.\n",
    "    \n",
    "    METRICS:\n",
    "    - MAPE (Mean Absolute Percentage Error): Primary metric used by\n",
    "      Gatabazi et al. (2019) to judge model quality\n",
    "      * MAPE < 10%: Highly accurate\n",
    "      * MAPE 10-20%: Good accuracy\n",
    "      * MAPE 20-50%: Reasonable accuracy\n",
    "      * MAPE > 50%: Poor accuracy\n",
    "    \n",
    "    - RMSE (Root Mean Squared Error): Economic interpretability in $B\n",
    "      Shows average forecast error in dollar terms\n",
    "    \n",
    "    - MAE (Mean Absolute Error): Robust to outliers, complements RMSE\n",
    "    \n",
    "    These combine statistical precision (MAPE) with economic\n",
    "    interpretability (RMSE in billions USD).\n",
    "    \"\"\"\n",
    "    mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    if not mask.any():\n",
    "        return dict(RMSE=np.nan, MAE=np.nan, MAPE=np.nan)\n",
    "\n",
    "    yt = y_true[mask]\n",
    "    yp = y_pred[mask]\n",
    "    err = yt - yp\n",
    "\n",
    "    rmse = float(np.sqrt(np.mean(err**2)))\n",
    "    mae  = float(np.mean(np.abs(err)))\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ape = np.abs(err) / np.abs(yt)\n",
    "        ape = ape[np.isfinite(ape)]\n",
    "        mape = float(np.mean(ape)*100) if len(ape) > 0 else np.nan\n",
    "\n",
    "    return dict(RMSE=rmse, MAE=mae, MAPE=mape)\n",
    "\n",
    "def approx_lyapunov(params: VFGLVMParams) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    OPTIONAL: Simplified Lyapunov-style indicator for chaos detection.\n",
    "    \n",
    "    Gatabazi et al. (2019) discuss Lyapunov exponents of the fitted LV\n",
    "    system to argue the dynamics are chaotic. In their reported results,\n",
    "    the exponents essentially match the leading growth terms a_i.\n",
    "    \n",
    "    INTERPRETATION:\n",
    "    - All λ_i > 0: Chaotic dynamics (sensitive dependence on initial conditions)\n",
    "    - Mixed signs: Complex dynamics with some stability\n",
    "    - All λ_i < 0: Stable equilibrium (no chaos)\n",
    "    \n",
    "    For gold vs crypto:\n",
    "    - Positive Lyapunov exponents confirm market dynamics are chaotic\n",
    "    - This justifies the need for adaptive memory (variable q(t))\n",
    "    - Standard fixed-parameter models fail in chaotic systems\n",
    "    \n",
    "    NOTE: This is NOT a full Lyapunov calculation (which requires\n",
    "    trajectory analysis). It's a quick heuristic based on linearization\n",
    "    at the trivial equilibrium, matching Gatabazi et al.'s approach.\n",
    "    \"\"\"\n",
    "    return params.a.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8249606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FIT AND EVALUATE VFGLVM FOR ONE FREQUENCY\n",
    "# ============================================================================\n",
    "\n",
    "def fit_vfglvm_frequency(panel_scaled: pd.DataFrame,\n",
    "                         panel_raw: pd.DataFrame,\n",
    "                         scale_info: Dict,\n",
    "                         freq_name: str,\n",
    "                         window_q: int,\n",
    "                         smooth_ma_q: int) -> Dict:\n",
    "    \"\"\"\n",
    "    Complete VFGLVM pipeline for one frequency.\n",
    "    \n",
    "    PROCESS:\n",
    "    1. Take scaled series for gold (x) and bitcoin (y)\n",
    "    2. Estimate q(t) from rolling slopes (Step 3)\n",
    "    3. Build fractional accumulation X^{[q(t)]} and background Z (Steps 2 & 4)\n",
    "    4. Fit VFGLVM params (Step 5)\n",
    "    5. Generate 1-step-ahead fitted series\n",
    "    6. Unscale back to USD using stored medians\n",
    "    7. Compute error metrics (MAPE, RMSE)\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - panel_scaled: Median-normalized asset levels\n",
    "    - panel_raw: Original USD levels (for final comparison)\n",
    "    - scale_info: Median values used for normalization\n",
    "    - freq_name: \"DAILY\", \"WEEKLY\", or \"MONTHLY\" (for logging)\n",
    "    - window_q: Rolling window for q(t) estimation\n",
    "    - smooth_ma_q: Smoothing window for q(t)\n",
    "    \n",
    "    RETURNS:\n",
    "    - Dictionary with fitted values, parameters, metrics, and diagnostics\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\n[{freq_name}] Fitting VFGLVM...\")\n",
    "\n",
    "    # Levels in scaled space: gold = x, bitcoin = y\n",
    "    levels = [\n",
    "        _as_array(panel_scaled[\"x\"].values),\n",
    "        _as_array(panel_scaled[\"y\"].values),\n",
    "    ]\n",
    "    X0_full = np.vstack(levels)\n",
    "\n",
    "    # --- Step 3: estimate q(t) from market dynamics\n",
    "    q_t = estimate_q_t(X0_full, window=window_q, smooth_ma=smooth_ma_q)\n",
    "    if not np.isfinite(q_t).any():\n",
    "        # fallback to constant memory\n",
    "        q_t = np.full(len(panel_scaled), 0.5)\n",
    "\n",
    "    # --- Step 2 + Step 4: fractional accumulation + background value\n",
    "    max_lag = _default_max_lag(len(panel_scaled))\n",
    "    Xq, Zq = build_Z_q(levels, q_t, max_lag=max_lag)\n",
    "\n",
    "    # --- Step 5: fit LV-style discrete dynamics\n",
    "    params = fit_vfglvm_params(levels, Zq, ridge_alpha=1e-5)\n",
    "\n",
    "    # --- Create in-sample fitted paths in *scaled units*\n",
    "    fitted_list = vfglvm_fitted_values(params, levels, Zq)\n",
    "\n",
    "    # --- Unscale back to USD using medians from this frequency\n",
    "    med_gold = scale_info[\"gold_median_usd\"]\n",
    "    med_btc  = scale_info[\"btc_median_usd\"]\n",
    "\n",
    "    gold_fitted_raw = fitted_list[0] * med_gold\n",
    "    btc_fitted_raw  = fitted_list[1] * med_btc\n",
    "\n",
    "    df_out = pd.DataFrame({\n",
    "        \"gold_actual\": panel_raw[\"gold_etf_mcap_usd\"],\n",
    "        \"gold_fitted\": gold_fitted_raw,\n",
    "        \"btc_actual\":  panel_raw[\"btc_mcap_usd\"],\n",
    "        \"btc_fitted\":  btc_fitted_raw,\n",
    "    }, index=panel_raw.index)\n",
    "\n",
    "    # --- Error metrics (MAPE like Gatabazi et al. (2019), plus RMSE in $B)\n",
    "    gold_metrics = metrics_levels(panel_raw[\"gold_etf_mcap_usd\"].values,\n",
    "                                  gold_fitted_raw)\n",
    "    btc_metrics  = metrics_levels(panel_raw[\"btc_mcap_usd\"].values,\n",
    "                                  btc_fitted_raw)\n",
    "\n",
    "    print(f\"   Gold:    MAPE={gold_metrics['MAPE']:.2f}%, \"\n",
    "          f\"RMSE=${gold_metrics['RMSE']/1e9:.2f}B\")\n",
    "    print(f\"   Bitcoin: MAPE={btc_metrics['MAPE']:.2f}%, \"\n",
    "          f\"RMSE=${btc_metrics['RMSE']/1e9:.2f}B\")\n",
    "\n",
    "    return {\n",
    "        \"df_fit\": df_out,\n",
    "        \"params\": params,\n",
    "        \"q_t\": q_t,\n",
    "        \"gold_mape\": gold_metrics['MAPE'],\n",
    "        \"gold_rmse\": gold_metrics['RMSE'],\n",
    "        \"btc_mape\": btc_metrics['MAPE'],\n",
    "        \"btc_rmse\": btc_metrics['RMSE'],\n",
    "        \"lyapunov_like\": approx_lyapunov(params),  # optional chaos hint\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cded0ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PLOTTING: 6-PANEL (Gold row, Bitcoin row) ACROSS FREQUENCIES\n",
    "# ============================================================================\n",
    "\n",
    "def plot_6_panel(results_daily,\n",
    "                 results_weekly,\n",
    "                 results_monthly):\n",
    "    \"\"\"\n",
    "    Make the 2x3 grid:\n",
    "        Top row  = Gold ETF AUM (Daily, Weekly, Monthly)\n",
    "        Bottom   = Bitcoin Market Cap (Daily, Weekly, Monthly)\n",
    "\n",
    "    Each subplot shows:\n",
    "        - Actual (in USD billions)\n",
    "        - VFGLVM fitted (1-step-ahead in USD billions)\n",
    "        - Text box with MAPE and RMSE\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "    # Row 1: Gold\n",
    "    for i, (freq_name, results) in enumerate([\n",
    "        (\"Daily\",   results_daily),\n",
    "        (\"Weekly\",  results_weekly),\n",
    "        (\"Monthly\", results_monthly),\n",
    "    ]):\n",
    "        ax = axes[0, i]\n",
    "        df = results[\"df_fit\"]\n",
    "\n",
    "        ax.plot(df.index,\n",
    "                df[\"gold_actual\"]/1e9,\n",
    "                label=\"Actual\",\n",
    "                lw=2,\n",
    "                alpha=0.7,\n",
    "                color='goldenrod')\n",
    "        ax.plot(df.index,\n",
    "                df[\"gold_fitted\"]/1e9,\n",
    "                label=\"VFGLVM\",\n",
    "                lw=1.5,\n",
    "                alpha=0.9,\n",
    "                linestyle='--',\n",
    "                color='darkgoldenrod')\n",
    "\n",
    "        ax.set_title(f\"Gold ETF AUM - {freq_name}\",\n",
    "                     fontsize=11,\n",
    "                     fontweight='bold')\n",
    "        ax.set_ylabel(\"Billions USD\", fontsize=10)\n",
    "        ax.legend(loc='best', fontsize=9)\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "        ax.text(\n",
    "            0.02, 0.98,\n",
    "            f\"MAPE: {results['gold_mape']:.1f}%\\n\"\n",
    "            f\"RMSE: ${results['gold_rmse']/1e9:.1f}B\",\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=9,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round',\n",
    "                      facecolor='wheat',\n",
    "                      alpha=0.6)\n",
    "        )\n",
    "\n",
    "    # Row 2: BTC\n",
    "    for i, (freq_name, results) in enumerate([\n",
    "        (\"Daily\",   results_daily),\n",
    "        (\"Weekly\",  results_weekly),\n",
    "        (\"Monthly\", results_monthly),\n",
    "    ]):\n",
    "        ax = axes[1, i]\n",
    "        df = results[\"df_fit\"]\n",
    "\n",
    "        ax.plot(df.index,\n",
    "                df[\"btc_actual\"]/1e9,\n",
    "                label=\"Actual\",\n",
    "                lw=2,\n",
    "                alpha=0.7,\n",
    "                color='steelblue')\n",
    "        ax.plot(df.index,\n",
    "                df[\"btc_fitted\"]/1e9,\n",
    "                label=\"VFGLVM\",\n",
    "                lw=1.5,\n",
    "                alpha=0.9,\n",
    "                linestyle='--',\n",
    "                color='navy')\n",
    "\n",
    "        ax.set_title(f\"Bitcoin Market Cap - {freq_name}\",\n",
    "                     fontsize=11,\n",
    "                     fontweight='bold')\n",
    "        ax.set_ylabel(\"Billions USD\", fontsize=10)\n",
    "        ax.set_xlabel(\"Date\", fontsize=10)\n",
    "        ax.legend(loc='best', fontsize=9)\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "        ax.text(\n",
    "            0.02, 0.98,\n",
    "            f\"MAPE: {results['btc_mape']:.1f}%\\n\"\n",
    "            f\"RMSE: ${results['btc_rmse']/1e9:.1f}B\",\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=9,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round',\n",
    "                      facecolor='lightblue',\n",
    "                      alpha=0.6)\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTDIR / \"vfglvm_6panel_comparison_gold_vs_btc.png\",\n",
    "                dpi=300,\n",
    "                bbox_inches=\"tight\")\n",
    "    print(f\"\\n✅ Saved: {OUTDIR / 'vfglvm_6panel_comparison_gold_vs_btc.png'}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c5f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MAIN PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" VFGLVM MULTI-FREQUENCY COMPARISON\")\n",
    "    print(\" GOLD ETF AUM vs BITCOIN ONLY\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # --- Build panels for each freq\n",
    "    panel_raw_monthly, panel_scaled_monthly, scale_monthly = build_monthly()\n",
    "    panel_raw_weekly,  panel_scaled_weekly,  scale_weekly  = build_weekly()\n",
    "    panel_raw_daily,   panel_scaled_daily,   scale_daily   = build_daily()\n",
    "\n",
    "    # --- Fit VFGLVM for each freq.\n",
    "    # We pick slightly different q(t) window/smoothing per freq.\n",
    "    results_monthly = fit_vfglvm_frequency(\n",
    "        panel_scaled_monthly, panel_raw_monthly, scale_monthly,\n",
    "        \"MONTHLY\", window_q=12, smooth_ma_q=4\n",
    "    )\n",
    "    results_weekly = fit_vfglvm_frequency(\n",
    "        panel_scaled_weekly, panel_raw_weekly, scale_weekly,\n",
    "        \"WEEKLY\", window_q=20, smooth_ma_q=6\n",
    "    )\n",
    "    results_daily = fit_vfglvm_frequency(\n",
    "        panel_scaled_daily, panel_raw_daily, scale_daily,\n",
    "        \"DAILY\", window_q=30, smooth_ma_q=8\n",
    "    )\n",
    "\n",
    "    # --- Visual comparison grid (6 subplots)\n",
    "    plot_6_panel(results_daily, results_weekly, results_monthly)\n",
    "\n",
    "    # --- PERFORMANCE SUMMARY TABLE\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    summary = pd.DataFrame([\n",
    "        {\"Frequency\": \"Monthly\", \"Asset\": \"Gold\",\n",
    "         \"MAPE_%\": results_monthly[\"gold_mape\"],\n",
    "         \"RMSE_B\": results_monthly[\"gold_rmse\"]/1e9},\n",
    "\n",
    "        {\"Frequency\": \"Monthly\", \"Asset\": \"Bitcoin\",\n",
    "         \"MAPE_%\": results_monthly[\"btc_mape\"],\n",
    "         \"RMSE_B\": results_monthly[\"btc_rmse\"]/1e9},\n",
    "\n",
    "        {\"Frequency\": \"Weekly\",  \"Asset\": \"Gold\",\n",
    "         \"MAPE_%\": results_weekly[\"gold_mape\"],\n",
    "         \"RMSE_B\": results_weekly[\"gold_rmse\"]/1e9},\n",
    "\n",
    "        {\"Frequency\": \"Weekly\",  \"Asset\": \"Bitcoin\",\n",
    "         \"MAPE_%\": results_weekly[\"btc_mape\"],\n",
    "         \"RMSE_B\": results_weekly[\"btc_rmse\"]/1e9},\n",
    "\n",
    "        {\"Frequency\": \"Daily\",   \"Asset\": \"Gold\",\n",
    "         \"MAPE_%\": results_daily[\"gold_mape\"],\n",
    "         \"RMSE_B\": results_daily[\"gold_rmse\"]/1e9},\n",
    "\n",
    "        {\"Frequency\": \"Daily\",   \"Asset\": \"Bitcoin\",\n",
    "         \"MAPE_%\": results_daily[\"btc_mape\"],\n",
    "         \"RMSE_B\": results_daily[\"btc_rmse\"]/1e9},\n",
    "    ])\n",
    "\n",
    "    print(\"\\n\", summary.round(2).to_string(index=False))\n",
    "    summary.to_csv(OUTDIR / \"performance_summary_gold_vs_btc.csv\",\n",
    "                   index=False)\n",
    "\n",
    "    # --- Save fitted paths (actual vs fitted)\n",
    "    results_monthly[\"df_fit\"].to_csv(\n",
    "        OUTDIR / \"fitted_monthly_gold_vs_btc.csv\")\n",
    "    results_weekly[\"df_fit\"].to_csv(\n",
    "        OUTDIR / \"fitted_weekly_gold_vs_btc.csv\")\n",
    "    results_daily[\"df_fit\"].to_csv(\n",
    "        OUTDIR / \"fitted_daily_gold_vs_btc.csv\")\n",
    "\n",
    "    # --- PARAMETER COMPARISON TABLE\n",
    "    # Interpretability:\n",
    "    #   a_gold ~ intrinsic growth of gold AUM\n",
    "    #   a_bitcoin ~ intrinsic growth of BTC cap\n",
    "    #   b_* ~ self-crowding / saturation\n",
    "    #   C_bitcoin_to_gold ~ effect of BTC on gold\n",
    "    #   C_gold_to_bitcoin ~ effect of gold on BTC\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" PARAMETER COMPARISON (Gold = series x, Bitcoin = series y)\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    param_df = pd.DataFrame({\n",
    "        \"Frequency\": [\"Monthly\", \"Weekly\", \"Daily\"],\n",
    "        \"a_gold\":    [results_monthly[\"params\"].a[0],\n",
    "                      results_weekly[\"params\"].a[0],\n",
    "                      results_daily[\"params\"].a[0]],\n",
    "        \"a_bitcoin\": [results_monthly[\"params\"].a[1],\n",
    "                      results_weekly[\"params\"].a[1],\n",
    "                      results_daily[\"params\"].a[1]],\n",
    "\n",
    "        \"b_gold\":    [results_monthly[\"params\"].b[0],\n",
    "                      results_weekly[\"params\"].b[0],\n",
    "                      results_daily[\"params\"].b[0]],\n",
    "        \"b_bitcoin\": [results_monthly[\"params\"].b[1],\n",
    "                      results_weekly[\"params\"].b[1],\n",
    "                      results_daily[\"params\"].b[1]],\n",
    "\n",
    "        # C[0,1] = impact of Bitcoin on Gold (crowd-out if +)\n",
    "        # C[1,0] = impact of Gold on Bitcoin\n",
    "        \"C_bitcoin_to_gold\": [results_monthly[\"params\"].C[0,1],\n",
    "                              results_weekly[\"params\"].C[0,1],\n",
    "                              results_daily[\"params\"].C[0,1]],\n",
    "        \"C_gold_to_bitcoin\": [results_monthly[\"params\"].C[1,0],\n",
    "                              results_weekly[\"params\"].C[1,0],\n",
    "                              results_daily[\"params\"].C[1,0]],\n",
    "\n",
    "        # optional chaos-ish \"growth rates\"\n",
    "        \"approx_lyapunov_gold\": [results_monthly[\"lyapunov_like\"][0],\n",
    "                                 results_weekly[\"lyapunov_like\"][0],\n",
    "                                 results_daily[\"lyapunov_like\"][0]],\n",
    "        \"approx_lyapunov_btc\":  [results_monthly[\"lyapunov_like\"][1],\n",
    "                                 results_weekly[\"lyapunov_like\"][1],\n",
    "                                 results_daily[\"lyapunov_like\"][1]],\n",
    "    })\n",
    "\n",
    "    print(\"\\n\", param_df.round(6).to_string(index=False))\n",
    "    param_df.to_csv(OUTDIR / \"parameter_comparison_gold_vs_btc.csv\",\n",
    "                    index=False)\n",
    "\n",
    "    print(\"\\n✅ All outputs saved to:\", OUTDIR)\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
